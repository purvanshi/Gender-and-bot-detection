{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = ['id', 'avg_ADJ', 'avg_ADP', 'avg_ADV', 'avg_AUX', 'avg_CCONJ', 'avg_CONJ', 'avg_DET', 'avg_EOL', 'avg_INTJ', 'avg_NOUN', 'avg_NO_TAG', 'avg_NUM', 'avg_PART', 'avg_PRON', 'avg_PROPN', 'avg_PUNCT', 'avg_SCONJ', 'avg_SPACE', 'avg_SYM', 'avg_Tops', 'avg_VERB', 'avg_X', 'avg_act', 'avg_adjectives_for_people', 'avg_animal', 'avg_april_fool', 'avg_art', 'avg_artifact', 'avg_astronomy', 'avg_attribute', 'avg_baseball', 'avg_bathroom', 'avg_beach', 'avg_big', 'avg_biomes', 'avg_birds', 'avg_birthday', 'avg_boat', 'avg_bodies_of_water', 'avg_body', 'avg_buildings', 'avg_camping', 'avg_car', 'avg_carnival', 'avg_carparts', 'avg_castle', 'avg_cats', 'avg_change', 'avg_christmas', 'avg_circus', 'avg_clothes', 'avg_cognition', 'avg_colors', 'avg_communication', 'avg_competition', 'avg_computer', 'avg_constitution', 'avg_consumption', 'avg_contact', 'avg_container', 'avg_cooking', 'avg_cooking_tools', 'avg_country', 'avg_creation', 'avg_dance', 'avg_dentist', 'avg_desserts', 'avg_doctor', 'avg_dogs', 'avg_driving', 'avg_election', 'avg_emotion', 'avg_emotions', 'avg_energy', 'avg_event', 'avg_fall', 'avg_family', 'avg_farm', 'avg_feeling', 'avg_fish', 'avg_flowers', 'avg_food', 'avg_foodweb', 'avg_fruit', 'avg_furniture', 'avg_geography', 'avg_grammar', 'avg_group', 'avg_happiness', 'avg_happy', 'avg_house', 'avg_housing', 'avg_insect', 'avg_jobs', 'avg_kitchen', 'avg_land_forms', 'avg_languages', 'avg_leaders', 'avg_legal', 'avg_location', 'avg_mammal', 'avg_many', 'avg_math', 'avg_maxWordAppearancePerTweet', 'avg_measurement', 'avg_metals', 'avg_military', 'avg_money', 'avg_motion', 'avg_motive', 'avg_music_theory', 'avg_musical_instruments', 'avg_mythical_beasts', 'avg_negative_words', 'avg_new_year', 'avg_noURL', 'avg_nocf', 'avg_noclPerWord', 'avg_noe', 'avg_nos', 'avg_now', 'avg_nowr', 'avg_object', 'avg_ocean', 'avg_office', 'avg_people', 'avg_perception', 'avg_person', 'avg_phenomenon', 'avg_pirate', 'avg_plant', 'avg_plants', 'avg_positive_words', 'avg_possession', 'avg_postal', 'avg_process', 'avg_quantity', 'avg_readabilityScore', 'avg_relation', 'avg_reptiles', 'avg_restaurant', 'avg_roadways', 'avg_rocks', 'avg_rooms', 'avg_school', 'avg_science', 'avg_sciences', 'avg_shape', 'avg_social', 'avg_state', 'avg_stative', 'avg_substance', 'avg_time', 'avg_tree', 'avg_vacation', 'avg_valentine', 'avg_vegetables', 'avg_virtues', 'avg_water', 'avg_weapons', 'avg_weather', 'avg_winter', 'avg_yard', 'maxWordAppearancePerProfile', 'bot', 'gender']\n",
    "# len(fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fName = ['id']\n",
    "# fName.extend(pickle.load(open(\"C:\\\\Users\\\\Vanda\\\\Documents\\\\PAN19\\\\data\\\\pan19-author-profiling-training-2019-01-28\\\\en_features\\\\profile\\\\feature_names.p\", \"rb\")))\n",
    "# fName.extend(['bot', 'gender'])\n",
    "# print(\"Number of features:\", len(fName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_dir = \"../pan19-author-profiling-training-2019-01-28/\"\n",
    "df = pd.read_csv(csv_dir+\"features.txt\", sep='\\t', header=None, names=fName, encoding='utf-8-sig')\n",
    "\n",
    "# df_train = pd.read_csv(csv_dir+\"train_features.txt\", sep='\\t', header=None, names=fName, encoding='utf-8-sig')\n",
    "# df_dev = pd.read_csv(csv_dir+\"dev_features.txt\", sep='\\t', header=None, names=fName, encoding='utf-8-sig')\n",
    "# df_test = pd.read_csv(csv_dir+\"test_features.txt\", sep='\\t', header=None, names=fName, encoding='utf-8-sig')\n",
    "# df_train.columns = fName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>avg_ADJ</th>\n",
       "      <th>avg_ADP</th>\n",
       "      <th>avg_ADV</th>\n",
       "      <th>avg_AUX</th>\n",
       "      <th>avg_CCONJ</th>\n",
       "      <th>avg_CONJ</th>\n",
       "      <th>avg_DET</th>\n",
       "      <th>avg_EOL</th>\n",
       "      <th>avg_INTJ</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_vegetables</th>\n",
       "      <th>avg_virtues</th>\n",
       "      <th>avg_water</th>\n",
       "      <th>avg_weapons</th>\n",
       "      <th>avg_weather</th>\n",
       "      <th>avg_winter</th>\n",
       "      <th>avg_yard</th>\n",
       "      <th>maxWordAppearancePerProfile</th>\n",
       "      <th>bot</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4528ea5e16ec0098de1ac9003df1c0c5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>95</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49a16428796c727a861cc15af56db49a</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>82</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d5af4bd2faa881fdec3f0c3257bff909</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>274</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14b7a5b602baf6242a35c105a500f69a</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>198</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ccbe6914a203b899882ef4a9e0ebccf1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>111</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  avg_ADJ  avg_ADP  avg_ADV  avg_AUX  \\\n",
       "0  4528ea5e16ec0098de1ac9003df1c0c5     1.65     2.13     0.65      0.0   \n",
       "1  49a16428796c727a861cc15af56db49a     1.05     0.73     0.99      0.0   \n",
       "2  d5af4bd2faa881fdec3f0c3257bff909     0.09     0.11     0.03      0.0   \n",
       "3  14b7a5b602baf6242a35c105a500f69a     2.26     2.65     0.61      0.0   \n",
       "4  ccbe6914a203b899882ef4a9e0ebccf1     0.99     0.72     0.79      0.0   \n",
       "\n",
       "   avg_CCONJ  avg_CONJ  avg_DET  avg_EOL  avg_INTJ  ...  avg_vegetables  \\\n",
       "0       0.35       0.0     0.79      0.0      0.05  ...            0.03   \n",
       "1       0.24       0.0     0.68      0.0      0.51  ...            0.00   \n",
       "2       0.02       0.0     0.00      0.0      0.00  ...            0.00   \n",
       "3       1.14       0.0     1.67      0.0      0.11  ...            0.00   \n",
       "4       0.11       0.0     0.65      0.0      0.14  ...            0.00   \n",
       "\n",
       "   avg_virtues  avg_water  avg_weapons  avg_weather  avg_winter  avg_yard  \\\n",
       "0         0.11       0.05         0.01         0.31        0.05      0.01   \n",
       "1         0.23       0.03         0.01         0.11        0.02      0.02   \n",
       "2         0.00       0.01         0.00         0.02        0.02      0.00   \n",
       "3         0.20       0.05         0.00         0.23        0.02      0.01   \n",
       "4         0.04       0.04         0.02         0.16        0.04      0.00   \n",
       "\n",
       "   maxWordAppearancePerProfile    bot  gender  \n",
       "0                           95  human  female  \n",
       "1                           82  human  female  \n",
       "2                          274    bot     bot  \n",
       "3                          198    bot     bot  \n",
       "4                          111  human    male  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(df):\n",
    "    nCols = df.shape[1]\n",
    "    nFeatures = nCols-3\n",
    "    X = df.iloc[:, 1:nFeatures+1]\n",
    "    y_bot = df.iloc[:, nFeatures+1]\n",
    "    y_gender = df.iloc[:, nFeatures+2]\n",
    "    X_train, X_test, y_train_bot, y_test_bot, y_train_gender, y_test_gender = train_test_split(X, y_bot, y_gender, test_size=0.33, random_state=42)\n",
    "    y_train_bot = y_train_bot.values\n",
    "    y_test_bot = y_test_bot.values\n",
    "    y_train_gender = y_train_gender.values\n",
    "    y_test_gender = y_test_gender.values\n",
    "    i2n = {ind: name for (ind, name) in enumerate(df.iloc[:, 0].tolist())}\n",
    "    n2i = {name: ind for (ind, name) in i2n.items()}\n",
    "    return X_train, X_test, y_train_bot, y_test_bot, y_train_gender, y_test_gender, i2n, n2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  (2760, 164) \n",
      "Test size:  (1360, 164)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train_bot, y_test_bot, y_train_gender, y_test_gender, i2n, n2i = getData(df)\n",
    "# X_train, y_train_bot, y_train_gender, train_i2n, train_n2i = getData(df_train)\n",
    "# X_dev, y_dev_bot, y_dev_gender, dev_i2n, dev_n2i = getData(df_dev)\n",
    "# X_test, y_test_bot, y_test_gender, test_i2n, test_n2i = getData(df_test)\n",
    "print('Train size: ', X_train.shape, '\\nTest size: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features(features, train, dev, test):\n",
    "    train_f = train[features]\n",
    "    dev_f = dev[features]\n",
    "    test_f = test[features]\n",
    "    return train_f, dev_f, test_f    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_features(features, df):\n",
    "    df.drop(columns=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train, X_test):\n",
    "    cols = X_train.columns\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train, columns=cols)\n",
    "    X_test = pd.DataFrame(X_test, columns=cols)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/mehta/multimodal/lib/python3.5/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/data/home/mehta/multimodal/lib/python3.5/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/data/home/mehta/multimodal/lib/python3.5/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns containing the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2760, 159)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nunique = X_train.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "X_train = X_train.drop(cols_to_drop, axis=1)\n",
    "# X_dev = X_dev.drop(cols_to_drop, axis=1)\n",
    "X_test = X_test.drop(cols_to_drop, axis=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2760, 159) (1360, 159)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_ADJ</th>\n",
       "      <th>avg_ADP</th>\n",
       "      <th>avg_ADV</th>\n",
       "      <th>avg_CCONJ</th>\n",
       "      <th>avg_DET</th>\n",
       "      <th>avg_INTJ</th>\n",
       "      <th>avg_NOUN</th>\n",
       "      <th>avg_NUM</th>\n",
       "      <th>avg_PART</th>\n",
       "      <th>avg_PRON</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_vacation</th>\n",
       "      <th>avg_valentine</th>\n",
       "      <th>avg_vegetables</th>\n",
       "      <th>avg_virtues</th>\n",
       "      <th>avg_water</th>\n",
       "      <th>avg_weapons</th>\n",
       "      <th>avg_weather</th>\n",
       "      <th>avg_winter</th>\n",
       "      <th>avg_yard</th>\n",
       "      <th>maxWordAppearancePerProfile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.769619</td>\n",
       "      <td>-0.536726</td>\n",
       "      <td>-0.048472</td>\n",
       "      <td>-0.364288</td>\n",
       "      <td>-0.285788</td>\n",
       "      <td>0.119490</td>\n",
       "      <td>-0.675813</td>\n",
       "      <td>-0.519862</td>\n",
       "      <td>-0.513928</td>\n",
       "      <td>0.466101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172815</td>\n",
       "      <td>0.204883</td>\n",
       "      <td>-0.342653</td>\n",
       "      <td>-1.227962</td>\n",
       "      <td>0.851707</td>\n",
       "      <td>-0.097740</td>\n",
       "      <td>0.173480</td>\n",
       "      <td>2.870484</td>\n",
       "      <td>-0.103494</td>\n",
       "      <td>-0.243642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.769619</td>\n",
       "      <td>0.086058</td>\n",
       "      <td>-1.375730</td>\n",
       "      <td>0.690363</td>\n",
       "      <td>-0.902910</td>\n",
       "      <td>-0.866097</td>\n",
       "      <td>-0.240968</td>\n",
       "      <td>-0.635628</td>\n",
       "      <td>-1.134919</td>\n",
       "      <td>-1.356078</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.130588</td>\n",
       "      <td>-1.135906</td>\n",
       "      <td>0.533016</td>\n",
       "      <td>-1.115473</td>\n",
       "      <td>-0.464113</td>\n",
       "      <td>-0.308987</td>\n",
       "      <td>-0.536781</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>0.396758</td>\n",
       "      <td>0.063524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.068415</td>\n",
       "      <td>0.245066</td>\n",
       "      <td>0.716388</td>\n",
       "      <td>-0.204492</td>\n",
       "      <td>0.387436</td>\n",
       "      <td>-0.487025</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>-0.172565</td>\n",
       "      <td>-0.084010</td>\n",
       "      <td>0.954521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210539</td>\n",
       "      <td>0.428348</td>\n",
       "      <td>0.533016</td>\n",
       "      <td>0.909325</td>\n",
       "      <td>-0.244809</td>\n",
       "      <td>0.113507</td>\n",
       "      <td>-0.181651</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.103494</td>\n",
       "      <td>0.088429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.726688</td>\n",
       "      <td>-1.252266</td>\n",
       "      <td>0.108999</td>\n",
       "      <td>-0.971511</td>\n",
       "      <td>-1.314324</td>\n",
       "      <td>-0.714468</td>\n",
       "      <td>-0.855423</td>\n",
       "      <td>-0.404096</td>\n",
       "      <td>-0.752771</td>\n",
       "      <td>-0.003532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287210</td>\n",
       "      <td>0.428348</td>\n",
       "      <td>-0.342653</td>\n",
       "      <td>1.246791</td>\n",
       "      <td>-0.683416</td>\n",
       "      <td>-0.308987</td>\n",
       "      <td>-0.980694</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.603746</td>\n",
       "      <td>-0.368169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.041514</td>\n",
       "      <td>-1.610035</td>\n",
       "      <td>-1.443217</td>\n",
       "      <td>-1.131307</td>\n",
       "      <td>-1.894045</td>\n",
       "      <td>-0.866097</td>\n",
       "      <td>-0.633274</td>\n",
       "      <td>-0.539156</td>\n",
       "      <td>-1.564837</td>\n",
       "      <td>-1.356078</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053918</td>\n",
       "      <td>-1.024173</td>\n",
       "      <td>-0.342653</td>\n",
       "      <td>-1.115473</td>\n",
       "      <td>-1.122023</td>\n",
       "      <td>-0.308987</td>\n",
       "      <td>-1.424607</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.603746</td>\n",
       "      <td>-1.140235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.039794</td>\n",
       "      <td>-0.298213</td>\n",
       "      <td>-0.858324</td>\n",
       "      <td>-0.012737</td>\n",
       "      <td>-0.697203</td>\n",
       "      <td>0.119490</td>\n",
       "      <td>0.898137</td>\n",
       "      <td>0.194026</td>\n",
       "      <td>-0.705002</td>\n",
       "      <td>-0.435596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517222</td>\n",
       "      <td>-0.018582</td>\n",
       "      <td>-0.342653</td>\n",
       "      <td>-0.778006</td>\n",
       "      <td>-0.244809</td>\n",
       "      <td>-0.308987</td>\n",
       "      <td>-0.714346</td>\n",
       "      <td>0.134075</td>\n",
       "      <td>-0.603746</td>\n",
       "      <td>1.341999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.512034</td>\n",
       "      <td>-0.470473</td>\n",
       "      <td>0.176487</td>\n",
       "      <td>-0.332329</td>\n",
       "      <td>-0.454094</td>\n",
       "      <td>-0.335396</td>\n",
       "      <td>-0.401672</td>\n",
       "      <td>-0.211154</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>-0.116245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709510</td>\n",
       "      <td>-0.018582</td>\n",
       "      <td>0.533016</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>-0.244809</td>\n",
       "      <td>-0.097740</td>\n",
       "      <td>-0.714346</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.603746</td>\n",
       "      <td>-0.642128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.869791</td>\n",
       "      <td>-0.947499</td>\n",
       "      <td>-0.453398</td>\n",
       "      <td>-0.524083</td>\n",
       "      <td>-0.304489</td>\n",
       "      <td>1.105077</td>\n",
       "      <td>-0.718352</td>\n",
       "      <td>-0.307625</td>\n",
       "      <td>-1.039382</td>\n",
       "      <td>-0.059889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210539</td>\n",
       "      <td>-0.018582</td>\n",
       "      <td>4.035692</td>\n",
       "      <td>-0.665518</td>\n",
       "      <td>-0.902719</td>\n",
       "      <td>-0.308987</td>\n",
       "      <td>-0.625564</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.603746</td>\n",
       "      <td>-0.550808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.454792</td>\n",
       "      <td>-0.284963</td>\n",
       "      <td>-0.475894</td>\n",
       "      <td>-0.651920</td>\n",
       "      <td>-0.547597</td>\n",
       "      <td>-0.259582</td>\n",
       "      <td>-0.231515</td>\n",
       "      <td>-0.384802</td>\n",
       "      <td>0.059295</td>\n",
       "      <td>-0.379240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172815</td>\n",
       "      <td>0.316616</td>\n",
       "      <td>-0.342653</td>\n",
       "      <td>-0.215563</td>\n",
       "      <td>-0.244809</td>\n",
       "      <td>-0.308987</td>\n",
       "      <td>0.173480</td>\n",
       "      <td>-0.286911</td>\n",
       "      <td>-0.103494</td>\n",
       "      <td>-0.384773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.383241</td>\n",
       "      <td>-0.192208</td>\n",
       "      <td>-0.183447</td>\n",
       "      <td>-0.556042</td>\n",
       "      <td>0.462238</td>\n",
       "      <td>-0.714468</td>\n",
       "      <td>-0.463117</td>\n",
       "      <td>-0.577745</td>\n",
       "      <td>-0.466159</td>\n",
       "      <td>-0.228957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440551</td>\n",
       "      <td>-0.688976</td>\n",
       "      <td>-0.342653</td>\n",
       "      <td>-0.553029</td>\n",
       "      <td>0.851707</td>\n",
       "      <td>0.536002</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>-0.076418</td>\n",
       "      <td>0.897010</td>\n",
       "      <td>-0.500998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    avg_ADJ   avg_ADP   avg_ADV  avg_CCONJ   avg_DET  avg_INTJ  avg_NOUN  \\\n",
       "0 -0.769619 -0.536726 -0.048472  -0.364288 -0.285788  0.119490 -0.675813   \n",
       "1 -0.769619  0.086058 -1.375730   0.690363 -0.902910 -0.866097 -0.240968   \n",
       "2 -0.068415  0.245066  0.716388  -0.204492  0.387436 -0.487025  0.014267   \n",
       "3 -0.726688 -1.252266  0.108999  -0.971511 -1.314324 -0.714468 -0.855423   \n",
       "4 -1.041514 -1.610035 -1.443217  -1.131307 -1.894045 -0.866097 -0.633274   \n",
       "5 -0.039794 -0.298213 -0.858324  -0.012737 -0.697203  0.119490  0.898137   \n",
       "6 -0.512034 -0.470473  0.176487  -0.332329 -0.454094 -0.335396 -0.401672   \n",
       "7 -0.869791 -0.947499 -0.453398  -0.524083 -0.304489  1.105077 -0.718352   \n",
       "8 -0.454792 -0.284963 -0.475894  -0.651920 -0.547597 -0.259582 -0.231515   \n",
       "9 -0.383241 -0.192208 -0.183447  -0.556042  0.462238 -0.714468 -0.463117   \n",
       "\n",
       "    avg_NUM  avg_PART  avg_PRON  ...  avg_vacation  avg_valentine  \\\n",
       "0 -0.519862 -0.513928  0.466101  ...      0.172815       0.204883   \n",
       "1 -0.635628 -1.134919 -1.356078  ...     -1.130588      -1.135906   \n",
       "2 -0.172565 -0.084010  0.954521  ...     -0.210539       0.428348   \n",
       "3 -0.404096 -0.752771 -0.003532  ...     -0.287210       0.428348   \n",
       "4 -0.539156 -1.564837 -1.356078  ...     -1.053918      -1.024173   \n",
       "5  0.194026 -0.705002 -0.435596  ...     -0.517222      -0.018582   \n",
       "6 -0.211154  0.011527 -0.116245  ...      0.709510      -0.018582   \n",
       "7 -0.307625 -1.039382 -0.059889  ...     -0.210539      -0.018582   \n",
       "8 -0.384802  0.059295 -0.379240  ...      0.172815       0.316616   \n",
       "9 -0.577745 -0.466159 -0.228957  ...     -0.440551      -0.688976   \n",
       "\n",
       "   avg_vegetables  avg_virtues  avg_water  avg_weapons  avg_weather  \\\n",
       "0       -0.342653    -1.227962   0.851707    -0.097740     0.173480   \n",
       "1        0.533016    -1.115473  -0.464113    -0.308987    -0.536781   \n",
       "2        0.533016     0.909325  -0.244809     0.113507    -0.181651   \n",
       "3       -0.342653     1.246791  -0.683416    -0.308987    -0.980694   \n",
       "4       -0.342653    -1.115473  -1.122023    -0.308987    -1.424607   \n",
       "5       -0.342653    -0.778006  -0.244809    -0.308987    -0.714346   \n",
       "6        0.533016     0.009415  -0.244809    -0.097740    -0.714346   \n",
       "7        4.035692    -0.665518  -0.902719    -0.308987    -0.625564   \n",
       "8       -0.342653    -0.215563  -0.244809    -0.308987     0.173480   \n",
       "9       -0.342653    -0.553029   0.851707     0.536002    -0.004085   \n",
       "\n",
       "   avg_winter  avg_yard  maxWordAppearancePerProfile  \n",
       "0    2.870484 -0.103494                    -0.243642  \n",
       "1   -0.286911  0.396758                     0.063524  \n",
       "2   -0.286911 -0.103494                     0.088429  \n",
       "3   -0.286911 -0.603746                    -0.368169  \n",
       "4   -0.286911 -0.603746                    -1.140235  \n",
       "5    0.134075 -0.603746                     1.341999  \n",
       "6   -0.286911 -0.603746                    -0.642128  \n",
       "7   -0.286911 -0.603746                    -0.550808  \n",
       "8   -0.286911 -0.103494                    -0.384773  \n",
       "9   -0.076418  0.897010                    -0.500998  \n",
       "\n",
       "[10 rows x 159 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(classifier_bot, classifier_gender):\n",
    "    classifier_bot.fit(X_train, y_train_bot)\n",
    "    y_pred_test_bot = classifier_bot.predict(X_test)\n",
    "    print(\"Bot classification\")\n",
    "    print(classification_report(y_test_bot, y_pred_test_bot))\n",
    "\n",
    "    # preparing for gender classification\n",
    "    y_pred_train_bot = classifier_bot.predict(X_train)\n",
    "    human_train_indices = [ind for ind, label in enumerate(y_pred_train_bot) if label=='human']\n",
    "    human_test_indices = [ind for ind, label in enumerate(y_pred_test_bot) if label=='human']\n",
    "    X_train_human = X_train.iloc[human_train_indices, :]\n",
    "    y_train_human_gender = y_train_gender[human_train_indices]\n",
    "    X_test_human = X_test.iloc[human_test_indices, :]\n",
    "    y_test_human_gender = y_test_gender[human_test_indices]\n",
    "\n",
    "    # Gender\n",
    "    classifier_gender.fit(X_train_human, y_train_human_gender)\n",
    "    y_pred_test_gender = classifier_gender.predict(X_test_human)\n",
    "    y_pred_test_gender_all  = y_pred_test_bot\n",
    "    y_pred_test_gender_all[human_test_indices] = y_pred_test_gender\n",
    "    print(\"Gender classification\")\n",
    "    print(classification_report(y_test_human_gender, y_pred_test_gender))\n",
    "    print(\"Genfer classification including bots\")\n",
    "    print(classification_report(y_test_gender, y_pred_test_gender_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.98      0.99       692\n",
      "       human       0.98      1.00      0.99       668\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1360\n",
      "   macro avg       0.99      0.99      0.99      1360\n",
      "weighted avg       0.99      0.99      0.99      1360\n",
      "\n",
      "Gender classification\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       0.00      0.00      0.00        14\n",
      "      female       0.85      0.92      0.88       328\n",
      "        male       0.91      0.87      0.89       338\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       680\n",
      "   macro avg       0.59      0.60      0.59       680\n",
      "weighted avg       0.86      0.88      0.87       680\n",
      "\n",
      "Genfer classification including bots\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bot       1.00      0.98      0.99       692\n",
      "      female       0.85      0.92      0.88       329\n",
      "        male       0.91      0.86      0.89       339\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1360\n",
      "   macro avg       0.92      0.92      0.92      1360\n",
      "weighted avg       0.94      0.94      0.94      1360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/mehta/multimodal/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "ada1 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=6), \n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=500,\n",
    "                         random_state=0)\n",
    "ada2 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=6), \n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=500,\n",
    "                         random_state=0)\n",
    "classify(ada1, ada2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "\n",
    "# save the classifier\n",
    "with open('ada1.pkl', 'wb') as fid:\n",
    "    cPickle.dump(ada1, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "\n",
    "# save the classifier\n",
    "with open('ada2.pkl', 'wb') as fid:\n",
    "    cPickle.dump(ada2, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal",
   "language": "python",
   "name": "multimodal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
